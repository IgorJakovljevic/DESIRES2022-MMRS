{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm as log_progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"Evaulation/Complex/F\"\n",
    "\n",
    "feature_path = \"Processed/UserChannel\"\n",
    "feature_files = [f for f in os.listdir(feature_path) if os.path.isfile(os.path.join(feature_path, f))]\n",
    "\n",
    "cluster_eval_files = []\n",
    "\n",
    "cluster_top_result = [0, None]\n",
    "for feature_file in feature_files:\n",
    "    cl_eval_path = os.path.join(eval_path,feature_file)\n",
    "    if(not os.path.exists(cl_eval_path)):\n",
    "        continue\n",
    "    cluster_eval_files = [f for f in os.listdir(cl_eval_path) if os.path.isfile(os.path.join(cl_eval_path, f))]\n",
    "    for cluster_file in cluster_eval_files:\n",
    "        pkl_file = os.path.join(cl_eval_path, cluster_file)\n",
    "        if(not os.path.exists(pkl_file)):\n",
    "            continue\n",
    "        eval_file_df = pd.read_pickle(pkl_file)\n",
    "        top_AUC=eval_file_df.groupby([\"name\"]).mean()['AUC'].sort_values(ascending=False).iloc[0]\n",
    "        if(top_AUC > cluster_top_result[0]):\n",
    "            cluster_top_result[0] = top_AUC\n",
    "            cluster_top_result[1] = pkl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_clustr_path = 'OrgUnitClustering.pkl'\n",
    "org_cluster_eval_df = pd.read_pickle(org_clustr_path)\n",
    "\n",
    "org_cluster_eval_desc_df = org_cluster_eval_df.groupby([\"name\"]).describe()\n",
    "display(org_cluster_eval_desc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_cluster_path = 'TeamsClustering.pkl'\n",
    "team_cluster_eval_df = pd.read_pickle(team_cluster_path)\n",
    "\n",
    "team_cluster_eval_desc_df = team_cluster_eval_df.groupby([\"name\"]).describe()\n",
    "display(team_cluster_eval_desc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \".\"\n",
    "eval_files = [f for f in os.listdir(eval_path) if os.path.isfile(os.path.join(eval_path, f)) and f.endswith(\".pkl\") and f.startswith(\"user\")]\n",
    "\n",
    "top_result = [0, None]\n",
    "for eval_file in log_progress(eval_files):    \n",
    "    eval_file_df = pd.read_pickle(eval_file).sort_values([\"AUC\"], ascending=False)\n",
    "    top_AUC = eval_file_df.iloc[0].AUC    \n",
    "    if(top_AUC > top_result[0]):\n",
    "        top_result[0] = top_AUC\n",
    "        top_result[1] = eval_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"Evaulation/Complex/F\"\n",
    "feature_path = \"Processed/UserChannel\"\n",
    "feature_files = [f for f in os.listdir(feature_path) if os.path.isfile(os.path.join(feature_path, f))]\n",
    "\n",
    "cluster_eval_files = [f for f in os.listdir(eval_path) if os.path.isfile(os.path.join(eval_path, f)) and f.endswith(\".pkl\") and f.startswith(\"clusters\")]\n",
    "\n",
    "cluster_top_result = [0, None]\n",
    "for eval_file in log_progress(cluster_eval_files):    \n",
    "    eval_file_df = pd.read_pickle(eval_file).groupby([\"name\"])\n",
    "    top_AUC = eval_file_df.describe()['AUC'].sort_values([\"mean\"], ascending=False).iloc[0]['mean']         \n",
    "    if(top_AUC > cluster_top_result[0]):\n",
    "        cluster_top_result[0] = top_AUC\n",
    "        cluster_top_result[1] = eval_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"Evaulation/Complex/Ego/\"\n",
    "\n",
    "\n",
    "eval_files = [os.path.join(eval_path, f) for f in os.listdir(eval_path) if os.path.isfile(os.path.join(eval_path, f))]\n",
    "eval_files.extend([os.path.join(\"Evaulation/Complex/\", f) for f in os.listdir(\"Evaulation/Complex\") if os.path.isfile(os.path.join(\"Evaulation/Complex\", f))])\n",
    "top_result = [0, None]\n",
    "for eval_file in log_progress(eval_files):    \n",
    "\n",
    "    eval_file_df = pd.read_pickle(eval_file).sort_values([\"AUC\"], ascending=False)\n",
    "    top_AUC = eval_file_df.iloc[0].AUC    \n",
    "\n",
    "    if(top_AUC > top_result[0]):\n",
    "        top_result[0] = top_AUC\n",
    "        top_result[1] = eval_file\n",
    "\n",
    "display(top_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"Evaulation/Simple/\"\n",
    "\n",
    "\n",
    "eval_files = [os.path.join(eval_path, f) for f in os.listdir(eval_path) if os.path.isfile(os.path.join(eval_path, f))]\n",
    "top_result = [0, None]\n",
    "for eval_file in log_progress(eval_files):    \n",
    "\n",
    "    eval_file_df = pd.read_pickle(eval_file).sort_values([\"AUC\"], ascending=False)\n",
    "    top_AUC = eval_file_df.iloc[0].AUC    \n",
    "\n",
    "    if(top_AUC > top_result[0]):\n",
    "        top_result[0] = top_AUC\n",
    "        top_result[1] = eval_file\n",
    "\n",
    "display(top_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c6710c6338c3a43678f1ef28d4c6ed63a77d410a91cdedd60b3283f85d762de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
